{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6787db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # Main PyTorch library\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim  # Optimization algorithms\n",
    "import torch.nn.functional as F  # Functions\n",
    "from torch.utils.data import DataLoader  # To load data\n",
    "from torch.utils.data import Dataset  # To create new Datasets\n",
    "from torchvision import datasets, transforms  # Datasets and image transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2b2d2d",
   "metadata": {},
   "source": [
    "# CNN convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b4d814",
   "metadata": {},
   "source": [
    "**Flow in the Model:**\n",
    "1. Input image is passed through convolutional layers with ReLU activation and max pooling.\n",
    "2. The resulting feature maps are flattened into a vector.\n",
    "3. The vector is passed through fully connected layers with ReLU and dropout for regularization.\n",
    "4. The final output is produced through the last fully connected layer (self.fc2), which in this case likely represents the predicted class (for a classification problem with 10 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f3c3200-4b2a-4889-8068-cbf7d8ee160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64*7*7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Flatten the tensor\n",
    "        x = x.view(-1, 64*7*7)\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b426f",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f071cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MlpNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MlpNet, self).__init__()\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 32)\n",
    "        self.fc6 = nn.Linear(32, 16)\n",
    "        self.fc7 = nn.Linear(16, 10)\n",
    "        \n",
    "        # Dropout layers with different probabilities\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.dropout2 = nn.Dropout(p=0.3)\n",
    "        self.dropout3 = nn.Dropout(p=0.4)\n",
    "        self.dropout4 = nn.Dropout(p=0.5)\n",
    "        self.dropout5 = nn.Dropout(p=0.6)\n",
    "        self.dropout6 = nn.Dropout(p=0.7)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten the tensor\n",
    "        x = x.view(-1, 28*28)\n",
    "        \n",
    "        # Fully connected layers with ReLU activation and dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.dropout4(x)\n",
    "        \n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.dropout5(x)\n",
    "        \n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = self.dropout6(x)\n",
    "        \n",
    "        # Final output layer (no activation here; logits will be passed to the loss function)\n",
    "        x = self.fc7(x)\n",
    "        \n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
