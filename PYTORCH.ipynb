{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af4a2a27-b310-40cc-8941-a02b89a7b27c",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35015ab5-376f-4fbd-bb2d-06f945ed86ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # Main PyTorch library\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim  # Optimization algorithms\n",
    "import torch.nn.functional as F  # Functions\n",
    "from torch.utils.data import DataLoader  # To load data\n",
    "from torch.utils.data import Dataset  # To create new Datasets\n",
    "from torchvision import datasets, transforms  # Datasets and image transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c3200-4b2a-4889-8068-cbf7d8ee160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class convNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(convNet, self).__init__()\n",
    "        # 1. nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, 1)  # 28x28x1 -> \n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1)  # 14x14x16 ->\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, 1)  # 7x7x32 ->\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(64*3*3, 128)  # First fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 10)      # Second fully connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.cn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.cn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\"\"\"\n",
    "    Detailed Breakdown\n",
    "x = self.cn1(x)\n",
    "\n",
    "Operation: Applies the first convolutional layer.\n",
    "Purpose: Extracts initial features from the input image (or tensor) using learned filters.\n",
    "x = F.relu(x)\n",
    "\n",
    "Operation: Applies the ReLU (Rectified Linear Unit) activation function.\n",
    "Purpose: Introduces non-linearity by setting all negative values to zero, allowing the network to learn more complex patterns.\n",
    "x = self.cn2(x)\n",
    "\n",
    "Operation: Applies the second convolutional layer.\n",
    "Purpose: Further extracts features from the activations produced by cn1.\n",
    "x = F.relu(x)\n",
    "\n",
    "Operation: Again, applies the ReLU activation.\n",
    "Purpose: Maintains non-linearity after the second convolution.\n",
    "x = self.cn3(x)\n",
    "\n",
    "Operation: Applies the third convolutional layer.\n",
    "Purpose: Extracts even higher-level features from the input.\n",
    "x = F.relu(x)\n",
    "\n",
    "Operation: Applies ReLU once more.\n",
    "Purpose: Ensures non-linear transformation after the third convolution.\n",
    "x = F.max_pool2d(x, 2)\n",
    "\n",
    "Operation: Applies 2D max pooling with a kernel size of 2.\n",
    "Purpose: Reduces the spatial dimensions (height and width) of the feature maps by taking the maximum value over each 2Ã—2 region. This helps in reducing computation and controls overfitting by providing a form of spatial invariance.\n",
    "x = self.dropout1(x)\n",
    "\n",
    "Operation: Applies the first dropout layer.\n",
    "Purpose: Randomly sets a fraction of the activations to zero (as defined when the dropout was initialized) during training. This regularizes the model and reduces the chance of overfitting.\n",
    "x = torch.flatten(x, 1)\n",
    "\n",
    "Operation: Flattens the output tensor, starting from dimension 1.\n",
    "Purpose: Converts the multi-dimensional feature maps into a single vector per sample, preparing the data for the fully connected layers. The batch dimension (dimension 0) is preserved.\n",
    "x = self.fc1(x)\n",
    "\n",
    "Operation: Passes the flattened vector through the first fully connected (dense) layer.\n",
    "Purpose: Learns higher-level combinations of the features extracted by the convolutional layers. The layer transforms the input from a higher-dimensional space (e.g., 576 features) into a lower-dimensional space (128 features in this case).\n",
    "x = F.relu(x)\n",
    "\n",
    "Operation: Applies the ReLU activation to the output of the fully connected layer.\n",
    "Purpose: Adds non-linearity after the dense layer, enabling the network to learn more complex relationships.\n",
    "x = self.dropout2(x)\n",
    "\n",
    "Operation: Applies the second dropout layer.\n",
    "Purpose: Further regularizes the model by randomly dropping neurons during training, which helps prevent overfitting.\n",
    "x = self.fc2(x)\n",
    "\n",
    "Operation: Passes the result through the second fully connected layer.\n",
    "Purpose: Maps the 128 features to the number of classes (e.g., 10 for a 10-class classification problem).\n",
    "output = F.log_softmax(x, dim=1)\n",
    "\n",
    "Operation: Applies the log softmax function along dimension 1.\n",
    "Purpose: Converts the raw class scores (logits) into log-probabilities. The log softmax is numerically more stable than the regular softmax and is often used in conjunction with the negative log likelihood loss (nn.NLLLoss).\n",
    "return output\n",
    "\n",
    "Operation: Returns the final output.\n",
    "Purpose: Provides the log-probabilities for each class as the prediction for each sample in the batch.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5fe681",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
